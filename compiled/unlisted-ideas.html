<!DOCTYPE html>
<html lang='en'>

<head>
<header id="header">
<a class="blogname" href="https://www.arya-k.dev">arya-k</a>
</header>
<title>Unlisted: NLP ideas</title>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<link id='stylesheet' rel='stylesheet' href='assets/style.css'>
<!-- Icons generated with https://realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="assets/imgs/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="assets/imgs/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="assets/imgs/favicon-16x16.png">
<link rel="manifest" href="assets/imgs/site.webmanifest">
<link rel="mask-icon" href="assets/imgs/safari-pinned-tab.svg" color="#133259">
<link rel="shortcut icon" href="assets/imgs/favicon.ico">
<meta name="msapplication-TileColor" content="#133259">
<meta name="msapplication-config" content="assets/imgs/browserconfig.xml">
<meta name="theme-color" content="#ffffff">
</head>

<body>
<h1>Unlisted: NLP ideas</h1>
<time>Jul 22, 2019</time>
<h2>Context for the conversation:</h2>
<ul>
<li>This is an idea i've been musing over for a bit</li>
<li>I don't have the technical know-how to be sure how to pursue it</li>
<li>I'm looking for someone with more expertise to suggest how I should pursue this-
<ul>
<li>Oh, talk to this person</li>
<li>Oh, you should google these things</li>
<li>I've already seen this, it's nothing new!</li>
</ul>
</li>
</ul>
<h2>Tools to help assist programmers:</h2>
<ul>
<li>Most fundamentally, the IDE</li>
<li>Typically offers coding suggessions via tab complete, etc.</li>
<li>So how does the code completion work?</li>
</ul>
<h2>Examples of code completion</h2>
<h3>The &quot;classic&quot; methods</h3>
<ol>
<li>
<p><a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a></p>
<ul>
<li>Goto definition</li>
<li>auto complete function names</li>
<li>in strongly typed languages -&gt; Type information</li>
</ul>
</li>
<li>
<p><a href="https://www.jetbrains.com/help/idea/auto-completing-code.html">IntelliJ Completion</a></p>
<ul>
<li>&quot;complete the names of classes, methods, fields, and keywords&quot;</li>
<li>within the visibility scope</li>
</ul>
</li>
<li>
<p><a href="http://groups.inf.ed.ac.uk/naturalize/#about">Naturalize</a> to analyze Java code style.</p>
<ul>
<li>Able to rename and reformat in accordance with a larger codebase</li>
<li>Trains a language model on the codebase</li>
<li>Evaluates that language model on the candidate files</li>
</ul>
</li>
</ol>
<h3>More modern approaches:</h3>
<ol>
<li>
<p><a href="https://web.stanford.edu/~chshah/files/contextual-code-completion.pdf">Paper from Stanford</a> that tries to use a &quot;word vector&quot; like approach:</p>
<ul>
<li>Tokenize, then create &quot;code vectors&quot;</li>
<li>Use a feed forward NN to predict the next token</li>
</ul>
</li>
<li>
<p><a href="https://tabnine.com/">TabNine</a> is a brilliant, but closed source tool.</p>
<ul>
<li>Can reccomend lines of code at once</li>
<li>Uses a &quot;context engine&quot; that is able to separate tokens from code samples, eg:
<ul>
<li><code>let Alpaca = new Alpaca(1, 2)</code> is recorded as <code>let $1 = new $1(1, 2)</code></li>
</ul>
</li>
<li>Using this analysis, able to generalize high quality predictions from small amounts of code.</li>
</ul>
</li>
<li>
<p>Microsoft, on <a href="https://www.microsoft.com/en-us/research/blog/learning-source-code/">Learning from Source Code</a></p>
<ul>
<li>Converts programs to Graphs (an extension of an AST) that allows for intelligent analysis</li>
<li>Can find bugs by being asked to predict the node that should appear in the graph, thus showing that the programmer probably meant <code>var1</code> instead of <code>var2</code></li>
<li>Led to <a href="https://devblogs.microsoft.com/visualstudio/introducing-visual-studio-intellicode/">Visual Studio Intellicode</a>
<ul>
<li>&quot;IntelliCode generates recommendations by using a machine-learning model that is trained on thousands of public codebases – today it uses over 2000 GitHub repos that each have more than 100 stars to ensure that you’re benefiting from best practices.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Facebook <a href="https://ai.facebook.com/blog/aroma-ml-for-code-recommendation/">Aroma</a></p>
<ul>
<li>Able to intelligently reccomend code snippets</li>
<li>Improves code documentation by intelligently clustering similar code samples</li>
<li>Graph theory and statistical approach at its core.</li>
<li>Can &quot;[figure] out idiomatic usage patterns&quot; automatically</li>
<li>&quot;engineers should be able to easily discover recurring coding patterns in a big codebase and learn from them&quot;</li>
</ul>
</li>
</ol>
<h2>Dataset limitations:</h2>
<ul>
<li>
<p>According to <a href="https://web.cs.ucdavis.edu/~devanbu/isDLgood.pdf">this paper</a> from UC Davis in 2018, traditional datasets often outperform ML ones.</p>
</li>
<li>
<p>I think it's because of a lack of varied data.</p>
</li>
<li>
<p>Results seem to be either really good, or really bad.</p>
</li>
<li>
<p>The problem is that code isn't as linear as writing- functions are referenced far away from each other.</p>
</li>
<li>
<p>We need to either vary the training, or change the model. Here I'll consider varying the training.</p>
</li>
</ul>
<h2>Ideas for augmenting source code databases:</h2>
<ul>
<li>We have ways of evaluating how good code is:
<ul>
<li><strong>Opinionated</strong>, eg. rustfmt, gofmt</li>
<li><strong>Unopinionated</strong>, eg. PEP8, Microsoft C#</li>
<li>We have linters and autoformatters, but there's still a lot of possible variability (order of functions, etc.)</li>
</ul>
</li>
</ul>
<blockquote>
<p>We could use these tools to ensure that any autogenerated code remains up to scratch</p>
</blockquote>
<ul>
<li>We have lots of ways of representing code:
<ul>
<li>Abstract Syntax Tree (rope, compilers, etc)</li>
<li>&quot;Code vectors&quot;</li>
<li>Basic Tokens</li>
<li>Microsoft's &quot;Graph&quot; approach</li>
</ul>
</li>
</ul>
<blockquote>
<p>We can apply well developed fields to &quot;edit code&quot; by changing to these abstract representations, and then back into code.</p>
</blockquote>
<ul>
<li>We have ways to evaluate competing versions of the same code
<ul>
<li>Facebook's Aroma library</li>
<li>TabNine's stochastic analysis</li>
</ul>
</li>
</ul>
<blockquote>
<p>These tools can suggest code snippets that do similar things, but look different, a. la <code>a = a + 1;</code> vs <code>a += 1</code>. It'll let us increase variability by swapping between them</p>
</blockquote>
<ul>
<li>We could even try full on custom code generation!
<ul>
<li>See TabNine's <a href="https://tabnine.com/blog/deep">Deep learning code completion</a></li>
<li>If we develop a robust &quot;code linting + fixing&quot; suite, we should be able to produce idiomatic, nonsensical code</li>
<li>See OpenAI's <a href="https://openai.com/blog/better-language-models/">Better Language Models and their implications</a></li>
</ul>
</li>
</ul>
<h2>Summary</h2>
<p>In summary, the idea is to rapidly augment code samples for modern <em>or</em> traditional approaches by rearranging their structure while preserving their style and goals. We could also explore nonsensical code generation to augment firther if the &quot;quality&quot; of the code can be preserved anyways. This would require a detailed analysis (no unused vars, etc.)</p>
</body>
</html>